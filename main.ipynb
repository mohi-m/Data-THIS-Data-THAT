{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synchrony Datathalon 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load all the datasets\n",
    "account_df = pd.read_csv('data/account_dim_20250325.csv')\n",
    "fraud_case_df = pd.read_csv('data/fraud_claim_case_20250325.csv')\n",
    "fraud_tran_df = pd.read_csv('data/fraud_claim_tran_20250325.csv')\n",
    "rams_df = pd.read_csv('data/rams_batch_cur_20250325.csv')\n",
    "statement_df = pd.read_csv('data/statement_fact_20250325.csv')\n",
    "syfid_df = pd.read_csv('data/syf_id_20250325.csv')\n",
    "transaction_df = pd.read_csv('data/transaction_fact_20250325.csv')\n",
    "wrld_transaction_df = pd.read_csv('data/wrld_stor_tran_fact_20250325.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Process functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the RAMS dataset\n",
    "def clean_rams(df):\n",
    "    # Convert date column to datetime format\n",
    "    df['cu_processing_date'] = pd.to_datetime(df['cu_processing_date'])\n",
    "\n",
    "    # Keep only the latest processing date for each account\n",
    "    latest_df = df.sort_values(by=['cu_processing_date'], ascending=False).drop_duplicates(subset=['cu_account_nbr'], keep='first')\n",
    "\n",
    "    # drop the ca_cash_bal_pct_crd_line column\n",
    "    df = df.drop(columns=['ca_cash_bal_pct_crd_line'])\n",
    "    # irrelevant column as the values are all 0\n",
    "\n",
    "    #drop the cu_nbr_days_dlq column\n",
    "    df = df.drop(columns=['cu_nbr_days_dlq'])\n",
    "    #redundant as theres a simialr column with months which is more useful\n",
    "\n",
    "    #drop the ca_cash_bal_pct_cash_line column\n",
    "    df = df.drop(columns=['ca_cash_bal_pct_cash_line'])\n",
    "\n",
    "    #For all values in column cu_crd_bureau_scr , replace the value 0 with median of the column cu_crd_bureau_scr\n",
    "    df['cu_crd_bureau_scr'] = df['cu_crd_bureau_scr'].replace(0, df['cu_crd_bureau_scr'].median())\n",
    "\n",
    "    #drop the column cu_next_crd_line_rev_date\n",
    "    df = df.drop(columns=['cu_next_crd_line_rev_date'])\n",
    "    #irrelevant column as majority values are 0\n",
    "\n",
    "    #dropping columns\n",
    "    useless_col = [\n",
    "        'cu_cur_balance',\n",
    "        'ca_mob',\n",
    "        'cu_rnd_nbr',\n",
    "        'rb_crd_gr_new_crd_gr',\n",
    "        'cu_processing_date',\n",
    "        'mo_tot_sales_array_1',\n",
    "        'mo_tot_sales_array_2',\n",
    "        'mo_tot_sales_array_3',\n",
    "        'mo_tot_sales_array_4',\n",
    "        'mo_tot_sales_array_5',\n",
    "        'mo_tot_sales_array_6'\n",
    "    ]\n",
    "\n",
    "    #Droping the above generated columns\n",
    "    df = df.drop(columns=useless_col)\n",
    "\n",
    "    # for the values 999999999999999 in cu_cash_line_am replace them with 20% of corresponding valur of cu_crd_bureau_scr column \n",
    "    df['cu_cash_line_am'] = df.apply(\n",
    "        lambda row: row['cu_crd_bureau_scr'] * 0.2 if row['cu_cash_line_am'] == 999999999999999 else row['cu_cash_line_am'],\n",
    "        axis=1\n",
    "    )\n",
    "    # round it off to 2 decimal places\n",
    "    df['cu_cash_line_am'] = df['cu_cash_line_am'].round(2)\n",
    "\n",
    "    #drop duplicate rows with duplicate values in the column cu_account_nbr\n",
    "    df = df.drop_duplicates(subset=['cu_account_nbr'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the account dataset\n",
    "def pre_process_accounts(df):\n",
    "    account_df = df.copy()\n",
    "\n",
    "    # replace all \\\\\\\"\\\\\\\" values with NaN\n",
    "    account_df.replace(r'\\\\\\\"', np.nan, regex=True, inplace=True)\n",
    "\n",
    "    # drop duplicate rows\n",
    "    account_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # drop useless columns\n",
    "    useless_column  = ['date_in_collection', # All values are null\n",
    "                       'special_finance_charge_ind', # All values are null\n",
    "                       'card_activation_date', # Redundant since we have card_activation_flag\n",
    "                       'ebill_ind', # Not usefull for computing credit_line increase\n",
    "                       'overlimit_type_flag', # All values are 0\n",
    "                       'external_status_reason_code' # Redundant with ext_status_reason_cd_desc\n",
    "                       ]\n",
    "    account_df.drop(columns=useless_column, inplace=True, errors='ignore')\n",
    "\n",
    "    # convert date columns to datetime\n",
    "    date_columns = ['open_date']\n",
    "    for col in date_columns:\n",
    "        account_df[col] = pd.to_datetime(account_df[col], errors='coerce')\n",
    "\n",
    "    # update the card_activation_flag to 0 or 1. Currently it has the following values: 0, 7, 8 and nan. 0 mean activated and the rest are not activated.\n",
    "    account_df['card_activation_flag'] = account_df['card_activation_flag'].replace({'0': 1, '7': 0, '8': 0, np.nan: 0})\n",
    "\n",
    "    # Create empty columns for each month\n",
    "    for i in range(12):\n",
    "        account_df[f\"Month_{i+1}\"] = account_df['payment_hist_1_12_mths'].apply(lambda x: x[i] if pd.notna(x) and i < len(x) else np.nan)\n",
    "\n",
    "    for i in range(12):\n",
    "        account_df[f\"Month_{i+13}\"] = account_df['payment_hist_13_24_mths'].apply(lambda x: x[i] if pd.notna(x) and i < len(x) else np.nan)\n",
    "\n",
    "    # Drop the original payment history columns\n",
    "    account_df.drop(columns=['payment_hist_1_12_mths', 'payment_hist_13_24_mths'], inplace=True)\n",
    "\n",
    "    # Update the employee_code column. Currently it has the following values: H, Y and empty/na/null. Y mean employee, H means high spending customer and empty/na/null means normal customer. I want a separate column for high spending customer and employee. The rest are normal customers.\n",
    "    account_df['high_spending_customer'] = account_df['employee_code'].replace({'H': 1, 'Y': 0, '': 0, np.nan: 0})\n",
    "    account_df['employee_code'] = account_df['employee_code'].replace({'Y': 1, 'H': 0, '': 0, np.nan: 0})\n",
    "\n",
    "    return account_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transaction_data(transaction_df):\n",
    "\n",
    "    uselss_column=[\n",
    "                'payment_type',\n",
    "                'transaction_return_cnt',\n",
    "                'transaction_sale_cnt',\n",
    "                'product_amt',\n",
    "                'product_qty',\n",
    "                'invoice_nbr',\n",
    "                'first_purchase_ind',\n",
    "                'adj_orgn_tran_dt',\n",
    "                'curr_markup_fee',\n",
    "                'fcr_amount',\n",
    "                'fcr_flag',\n",
    "                'fcr_rate_of_exchange',\n",
    "                'posting_date']\n",
    "    \n",
    "    #drop the useless columns\n",
    "    transaction_df.drop(uselss_column,axis=1,inplace=True)\n",
    "\n",
    "    return transaction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply all the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h7/qn2fn7996dn7y9sp2_ptj5h40000gn/T/ipykernel_7259/823880188.py:24: FutureWarning: In a future version of pandas, parsing datetimes with mixed time zones will raise an error unless `utc=True`. Please specify `utc=True` to opt in to the new behaviour and silence this warning. To create a `Series` with mixed offsets and `object` dtype, please use `apply` and `datetime.datetime.strptime`\n",
      "  account_df[col] = pd.to_datetime(account_df[col], errors='coerce')\n",
      "/var/folders/h7/qn2fn7996dn7y9sp2_ptj5h40000gn/T/ipykernel_7259/823880188.py:27: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  account_df['card_activation_flag'] = account_df['card_activation_flag'].replace({'0': 1, '7': 0, '8': 0, np.nan: 0})\n",
      "/var/folders/h7/qn2fn7996dn7y9sp2_ptj5h40000gn/T/ipykernel_7259/823880188.py:40: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  account_df['high_spending_customer'] = account_df['employee_code'].replace({'H': 1, 'Y': 0, '': 0, np.nan: 0})\n",
      "/var/folders/h7/qn2fn7996dn7y9sp2_ptj5h40000gn/T/ipykernel_7259/823880188.py:41: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  account_df['employee_code'] = account_df['employee_code'].replace({'Y': 1, 'H': 0, '': 0, np.nan: 0})\n"
     ]
    }
   ],
   "source": [
    "updated_rams_df = clean_rams(rams_df)\n",
    "updated_accounts_df = pre_process_accounts(account_df)\n",
    "updated_transaction_df=clean_transaction_data(transaction_df)\n",
    "updated_world_transaction_df=clean_transaction_data(wrld_transaction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>current_account_nbr</th>\n",
       "      <th>transaction_type</th>\n",
       "      <th>transaction_code</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>transaction_amt</th>\n",
       "      <th>frgn_curr_code</th>\n",
       "      <th>frgn_tran_amt</th>\n",
       "      <th>us_equiv_amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X7jfKh6xrPAB8Tx6</td>\n",
       "      <td>SALE</td>\n",
       "      <td>253</td>\n",
       "      <td>2024-06-05</td>\n",
       "      <td>15.78</td>\n",
       "      <td>840</td>\n",
       "      <td>15.78</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yntD77AZDylS48Q4</td>\n",
       "      <td>SALE</td>\n",
       "      <td>253</td>\n",
       "      <td>2024-06-19</td>\n",
       "      <td>14.85</td>\n",
       "      <td>840</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIJPI0sK28Pa7fX2</td>\n",
       "      <td>SALE</td>\n",
       "      <td>253</td>\n",
       "      <td>2024-06-26</td>\n",
       "      <td>136.16</td>\n",
       "      <td>840</td>\n",
       "      <td>136.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CMAr5Apxwdzpvoze</td>\n",
       "      <td>SALE</td>\n",
       "      <td>253</td>\n",
       "      <td>2024-08-15</td>\n",
       "      <td>8.74</td>\n",
       "      <td>840</td>\n",
       "      <td>8.74</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eJSfTCGPvJulGzd3</td>\n",
       "      <td>SALE</td>\n",
       "      <td>253</td>\n",
       "      <td>2024-08-17</td>\n",
       "      <td>26.65</td>\n",
       "      <td>840</td>\n",
       "      <td>26.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  current_account_nbr transaction_type  transaction_code transaction_date  \\\n",
       "0    X7jfKh6xrPAB8Tx6             SALE               253       2024-06-05   \n",
       "1    yntD77AZDylS48Q4             SALE               253       2024-06-19   \n",
       "2    LIJPI0sK28Pa7fX2             SALE               253       2024-06-26   \n",
       "3    CMAr5Apxwdzpvoze             SALE               253       2024-08-15   \n",
       "4    eJSfTCGPvJulGzd3             SALE               253       2024-08-17   \n",
       "\n",
       "   transaction_amt frgn_curr_code  frgn_tran_amt  us_equiv_amt  \n",
       "0            15.78            840          15.78           0.0  \n",
       "1            14.85            840          14.85           0.0  \n",
       "2           136.16            840         136.16           0.0  \n",
       "3             8.74            840           8.74           0.0  \n",
       "4            26.65            840          26.65           0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_transaction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
